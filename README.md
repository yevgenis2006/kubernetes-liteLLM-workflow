<img width="960" height="532" alt="460220361-eb67af3c-6496-4ac6-9b2e-858c917ffbb8" src="https://github.com/user-attachments/assets/b1ddcc59-ca08-4c17-bb55-27645e55cf2f" />


## Kubernetes AI Foundation LiteLLM | â˜¸ï¸
Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] 

ğŸ¯ Features
```
Security:
âœ… SSO for Admin UI
âœ… Audit Logs with retention policy
âœ… JWT-Auth
âœ… Control available public, private routes (Restrict certain endpoints on proxy)
âœ… Control available public, private routes
âœ… Secret Managers - AWS Key Manager, Google Secret Manager, Azure Key, Hashicorp Vault
âœ… [BETA] AWS Key Manager v2 - Key Decryption
âœ… IP addressâ€‘based access control lists
âœ… Track Request IP Address
âœ… Use LiteLLM keys/authentication on Pass Through Endpoints
âœ… Set Max Request Size / File Size on Requests
âœ… Enforce Required Params for LLM Requests (ex. Reject requests missing ["metadata"]["generation_name"])
âœ… Key Rotations

Customize Logging, Guardrails, Caching per project:
âœ… Team Based Logging - Allow each team to use their own Langfuse Project / custom callbacks
âœ… Disable Logging for a Team - Switch off all logging for a team/project (GDPR Compliance)

Spend Tracking & Data Exports
âœ… Set USD Budgets Spend for Custom Tags
âœ… Set Model budgets for Virtual Keys
âœ… Exporting LLM Logs to GCS Bucket, Azure Blob Storage
âœ… /spend/report API endpoint

Prometheus Metrics:
âœ… Prometheus Metrics - Num Requests, failures, LLM Provider Outages
âœ… x-ratelimit-remaining-requests, x-ratelimit-remaining-tokens for LLM APIs on Prometheus

Custom Branding
âœ… Custom Branding + Routes on Swagger Docs
âœ… Public Model Hub
âœ… Custom Email Branding
```

ğŸ”¨ Example : 

```
from litellm import completion
import os
## set ENV variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"

messages = [{ "content": "Hello, how are you?","role": "user"}]

# openai call
response = completion(model="openai/gpt-4o", messages=messages)

# anthropic call
response = completion(model="anthropic/claude-sonnet-4-20250514", messages=messages)
print(response)
---
